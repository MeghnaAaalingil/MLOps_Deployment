version: '3'
services:
  prediction_api:
    build: .
    container_name: 'inference'
    ports:
      - '8000:8000'